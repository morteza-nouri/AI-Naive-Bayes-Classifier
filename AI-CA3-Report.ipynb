{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515384f9",
   "metadata": {},
   "source": [
    "# Artificial Intelligence :  Computer Assignment 3 - Naive Bayes Classifier\n",
    "> __Morteza Nouri, 810198481__\n",
    "\n",
    "## Goals:\n",
    "- Usage of Naive Bayes theorem\n",
    "- analyzing and classifying text\n",
    "- \n",
    "\n",
    "## Description:\n",
    "> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471e16fb",
   "metadata": {},
   "source": [
    "## Part 1: Preprocess\n",
    "In this part I use [hazm library](https://www.roshan-ai.ir/hazm/) to process persian text in dataset. At first I remove all useless words(stopwords and punctuations) in the data then processing text using methods below:<br>\n",
    "- __Normalization:__ normalize and adjust spaces.\n",
    "- __Steamming:__ remove prefix and postfix of a word to find it's root.\n",
    "- __Lemmatization__: except removing postfix and prefix of word, it will verify that root to be correct in meaning.\n",
    " \n",
    " __Q1__: In our text we might see a word in different forms(e.g. Plural, singular), but they are from same root and can have same effect in our classification. According to methods mentiond above, I decide to use Normalization and Lemmatization. Lemmatization gives us __Bon-e-Maazi__ and __Bon-e-Mozare__ of a verb in persian language and two words which have same root, in most cases have same concept.<br>\n",
    " _Note: Steaming is not accurate, because in some cases it destructs the normal form of the word. So I prefer to use Lemmatization instead that gives better perfomance and reduces the count of words in our bag._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4186832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "from hazm import *\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DataPreprocessor:\n",
    "    normalizer = Normalizer()\n",
    "    lemmatizer = Lemmatizer()\n",
    "    tokenizer = WordTokenizer()\n",
    "    useless_words = stopwords_list() + ['.', '،', '؛', '[', ']', '{', '}', '(', ')', '?', '!', ':', '\\\"', '\\'', '*', '/', '+',\n",
    "       '%', '#','-', '_', '\\r\\n', '\\n', '«', '»', '۹', '۸', '۷', '۶', '۵', '۴', '۳', '۲', '۱','.']\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def preprocess(self):\n",
    "        for i in range(len(self.dataset)):\n",
    "            self.dataset['content'][i] = self.__preprocess_util(self.dataset['content'][i])\n",
    "        return self.dataset\n",
    "    \n",
    "    def __preprocess_util(self, text):\n",
    "        text = self.normalizer.normalize(text)\n",
    "        text = self.tokenizer.tokenize(text)\n",
    "        words = [self.lemmatizer.lemmatize(word) for word in text if not (word in self.useless_words)]\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7625885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[فیلم, اکران, موزیکال, شاد, خاله, قورباغه, بزر...</td>\n",
       "      <td>هنر و سینما</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[فیلمسازی, کوئنتین, تارانتینو, عاشق, سینما, کم...</td>\n",
       "      <td>هنر و سینما</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[جان, آیو, اپل, جان, آیو, نیاز, معرف, تقریبا, ...</td>\n",
       "      <td>علم و تکنولوژی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[احتمال, پشتیبان, iOS, ۱۳, آیفون, اس, SE, آیفو...</td>\n",
       "      <td>علم و تکنولوژی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[دزد, مغازه, نماینده, ژاپن, اسکار, ۲۰۱۹, فیلم,...</td>\n",
       "      <td>هنر و سینما</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>[امپراطوری, اپ, فصل, اول/بخش, فصل, –, دوماپ, ,...</td>\n",
       "      <td>سلامت و زیبایی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>[ارتباطات, اثربخش, تعارض, محیط, کار, سازمان, و...</td>\n",
       "      <td>سلامت و زیبایی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>[اپل, سال, ۲۰۲۰, آیفون, معرف, گزارش, JPMorgan,...</td>\n",
       "      <td>علم و تکنولوژی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5198</th>\n",
       "      <td>[مارتینز, بلژیک, مقابل, فرانسه, ترس, بازی, سرم...</td>\n",
       "      <td>سلامت و زیبایی</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>[شیائومی, تاریخ, عرضه, گوش, گیمینگ, Black, Sha...</td>\n",
       "      <td>علم و تکنولوژی</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content           label\n",
       "0     [فیلم, اکران, موزیکال, شاد, خاله, قورباغه, بزر...     هنر و سینما\n",
       "1     [فیلمسازی, کوئنتین, تارانتینو, عاشق, سینما, کم...     هنر و سینما\n",
       "2     [جان, آیو, اپل, جان, آیو, نیاز, معرف, تقریبا, ...  علم و تکنولوژی\n",
       "3     [احتمال, پشتیبان, iOS, ۱۳, آیفون, اس, SE, آیفو...  علم و تکنولوژی\n",
       "4     [دزد, مغازه, نماینده, ژاپن, اسکار, ۲۰۱۹, فیلم,...     هنر و سینما\n",
       "...                                                 ...             ...\n",
       "5195  [امپراطوری, اپ, فصل, اول/بخش, فصل, –, دوماپ, ,...  سلامت و زیبایی\n",
       "5196  [ارتباطات, اثربخش, تعارض, محیط, کار, سازمان, و...  سلامت و زیبایی\n",
       "5197  [اپل, سال, ۲۰۲۰, آیفون, معرف, گزارش, JPMorgan,...  علم و تکنولوژی\n",
       "5198  [مارتینز, بلژیک, مقابل, فرانسه, ترس, بازی, سرم...  سلامت و زیبایی\n",
       "5199  [شیائومی, تاریخ, عرضه, گوش, گیمینگ, Black, Sha...  علم و تکنولوژی\n",
       "\n",
       "[5200 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('Data/train.csv')\n",
    "train_data['content'].fillna(train_data['label'], inplace=True)\n",
    "\n",
    "data_preprocessor = DataPreprocessor(train_data)\n",
    "clean_train_df = data_preprocessor.preprocess()\n",
    "clean_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e978129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
